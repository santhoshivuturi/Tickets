package SanthoshiShetty.volume;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.FloatWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

public class IdentityMapReduce {

		public static void main(String[] args) throws Exception{
			Configuration conf = new Configuration();
			Job job = new Job(conf, "Identity Map and Reduce Job-1");
			String[] otherArgs = new GenericOptionsParser(args).getRemainingArgs();
			if(otherArgs.length != 2) {
				System.err.println("Identity Job: Usage <in> <out>");
				System.exit(2);
			}
			job.setJarByClass(IdentityMapReduce.class);

			FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
			FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
			System.exit(job.waitForCompletion(true) ? 0 : 1);

		}
	}
